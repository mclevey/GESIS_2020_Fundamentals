{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Analysis with Python \n",
    "\n",
    "## Day 3: Scientific Computing with NumPy, Pandas, Matplotlib, and Seaborn \n",
    "\n",
    "49th [GESIS Spring Seminar: Digital Behavioral Data](https://training.gesis.org/?site=pDetails&pID=0xA33E4024A2554302B3EF4AECFC3484FD)   \n",
    "Cologne, Germany, March 2-6 2010\n",
    "\n",
    "### Course Developers and Instructors \n",
    "\n",
    "* Dr. [John McLevey](www.johnmclevey.com), University of Waterloo (john.mclevey@uwaterloo.ca)     \n",
    "* [Jillian Anderson](https://ca.linkedin.com/in/jillian-anderson-34435714a?challengeId=AQGaFXECVnyVqAAAAW_TLnwJ9VHAlBfinArnfKV6DqlEBpTIolp6O2Bau4MmjzZNgXlHqEIpS5piD4nNjEy0wsqNo-aZGkj57A&submissionId=16582ced-1f90-ec15-cddf-eb876f4fe004), Simon Fraser University (jillianderson8@gmail.com) \n",
    "\n",
    "<hr>\n",
    "\n",
    "### Overview \n",
    "\n",
    "High-level overview coming soon... \n",
    "\n",
    "### Plan for the Day\n",
    "\n",
    "1. [Introduction to NumPy](#numpy)\n",
    "    * Arrays \n",
    "2. [Introduction to Pandas](#pandas)\n",
    "    * Series \n",
    "    * Dataframes \n",
    "    * Groupby and descriptive statistics\n",
    "3. [Simple Data Visualization](#viz)\n",
    "    * A gentle introduction to Matplotlib \n",
    "    * Data Visualization with Seaborn \n",
    "4. [Best practices when working with Pandas Series and DataFrames](#pandasbp)\n",
    "    * Understanding how data is stored in Pandas\n",
    "    * Initialization\n",
    "    * Transformation\n",
    "5. [Open Work Time](#open)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NumPy<a id='numpy'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas<a id='pandas'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Data Visualization<a id='viz'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best practices when working with Pandas Series and DataFrames <a id='pandasbp'></a>\n",
    "\n",
    "From [pandas](https://pandas.pydata.org/):\n",
    ">pandas is a **fast**, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. \n",
    "\n",
    "This is all true, with a pretty large caveat. Pandas is fast (and generally efficient), if you avoid some of the common pitfalls. Unfortunately, these traps are easy to fall for and many pandas users (even senior data scientists) don't know they might be slowing their code down 10-1000x. These people will often be hesitant to use pandas on large datasets and may dissuade others from using the library. \n",
    "\n",
    "However, by understanding a little about what is going on in the backend, we can avoid the worst of the problems and write relatively fast pandas code. \n",
    "\n",
    "[How is data stored in pandas?](#storage)   \n",
    "[Efficient Transformation](#transform)   \n",
    "[Efficient Initialization](#init)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is data stored in Pandas? <a id='storage'></a>\n",
    "\n",
    "<h3><font color='tomato'>### Series</font></h3>\n",
    "\n",
    "### DataFrames\n",
    "DataFrames are really just a collection of Series, with each column corresponding to its own Series. As we mentioned above, each item in a Series (or column) is stored right after the one before it. This means that the entire column is stored within a single range of memory.\n",
    "\n",
    "However, the multiple Series (columns) that make a DataFrame can be stored anywhere in memory and are often not stored side-by-side. \n",
    "\n",
    "We can think of this like a grocery list for sandwiches. Lets imagine that each kind of sandwich we make is composed of 1 type of bread, 1 type of  meat and 1 type of vegetable. We could arrange our grocery list into a table like this: \n",
    "\n",
    "| sandwich_id | bread_type | meat_type  | vegetable_type |\n",
    "|-------------|------------|------------|----------------|\n",
    "| 0           | sourdough  | ham        | lettuce        |\n",
    "| 1           | baguette   | turkey     | tomato         |\n",
    "| 2           | rye        | roast beef | onion          |\n",
    "\n",
    "We buy all of our bread products from a bakery, meat from a deli, and vegetables from a grocer. The result is that to get everything in a column, you can go to one location (e.g. bakery for bread_type). But to get everything from a row you will have to visit all three locations. \n",
    "\n",
    "This means that is it really fast to access an entire column, but really slow to access a row. Lets check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Aside**   \n",
    ">In the code above, the `%%timeit` line is called a [magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#). The `timeit` magic lets us time the execution of a Python statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column\\n------\")\n",
    "%timeit sl = iris['petal_length']\n",
    "\n",
    "print(\"Row\\n------\")\n",
    "%timeit example_1 = iris.iloc[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This difference in speed is more than a 50x difference! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations <a id='transform'></a>\n",
    "One instance where the underlying storage structure and its consquence on speed is when applying transformations (calculations or other functions) to a DataFrame. \n",
    "\n",
    "A common case of this is when we want to add a new column to our DataFrame based on values in other columns. For example, we may want to:  \n",
    "* Extract month from a data column\n",
    "* Calculate area from width & length columns\n",
    "* Predict whether a flight will be late by applying a deep learning model to the values of 5 other columns. \n",
    "\n",
    "There is a long list of transformations we might be interested in, many of which operate on a single row, independent of other rows. \n",
    "\n",
    "There are many ways to implement transformations in pandas, some of which take advantage of how DataFrames are stored and others that do not. Below, we are going to look at __X__ methods for implementing transformations:\n",
    "1. [For Loops](#for)\n",
    "2. [`iterrows`](#iter)\n",
    "2. [Apply Method](#apply)\n",
    "3. [Zip & Iterate]\n",
    "4. \n",
    "\n",
    "We will use a common example across transformation methods allowing us to compare the speed of each one. For each method we will create a new column called `petal_area` by multiplying `petal_length` by `petal_width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width     species\n",
       "94           5.6          2.7           4.2          1.3  versicolor\n",
       "7            5.0          3.4           1.5          0.2      setosa\n",
       "12           4.8          3.0           1.4          0.1      setosa\n",
       "75           6.6          3.0           4.4          1.4  versicolor\n",
       "14           5.8          4.0           1.2          0.2      setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup code -- ideally this is changed to a dataset we are using \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "iris.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 For Loops <a id='for'></a>\n",
    "One possible method we can use to create this new column is to go row-by-row through the dataframe using a [for loop](01_introduction.ipynb#conditional).\n",
    "\n",
    "For each row in the data frame we will calculate the area for that example by multiplying `petal_length` by `petal_width` and placing the result in a Series that would eventually be added as a column to the DataFrame.\n",
    "\n",
    "Perhaps one of the most obvious ways to approach a transformation is to go row-by-row through the dataframe, doing the necessary transformations one at a time. A simple way to do this is using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.9 ms ± 292 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Looping over the rows\n",
    "area_column = []\n",
    "for i in range(0, len(iris)):\n",
    "    row = iris.loc[i]\n",
    "    row_area = row['petal_length'] * row['petal_width']\n",
    "    area_column.append(row_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we haven't checked any other methods yet, I'll let you know that this is _really_ slow. If we think about how DataFrames are stored it becomes clear why this is so slow. \n",
    "\n",
    "Before I get into this, lets look at the second method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  `iterrows()` <a id='iter'></a>\n",
    "A second method we can use to add our new column is using the `iterrows()` method ([docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows)). This is a built-in method pandas has implemented to iterate over the rows in a  DataFrame. \n",
    "\n",
    "This method creates a [generator object](https://wiki.python.org/moin/Generators), a special Python object, which we can use a for loop to iterate over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.9 ms ± 329 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "area_column = []\n",
    "for idx, row in iris.iterrows():\n",
    "    row_area = row['petal_length'] * row['petal_width']\n",
    "    area_column.append(row_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this was definitely faster than the basic [for loop](#for) approach, its still really slow. In fact, the underlying reason why these two approaches are so slow is the same.\n",
    "\n",
    "Both approaches use a `for` loops to go row-by-row through the DataFrame. Gathering the data for that row as its needed. \n",
    "\n",
    "In our sandwich example, this is the equivalent of buying ingredients for sandwich 1, then buying ingredients for sandwich 2, etc. This results in visiting each shop (bakery, deli, grocer) once for every sandwich recipe!\n",
    "\n",
    "The same thing is happening in pandas. To iterate over the rows using a for loop we retreive all values for row 1, then all values for row 2, etc. \n",
    "\n",
    "This is incredibly inefficient (imagine the funny looks you'd get on your 3rd visit to the bakery)! In fact, I would venture to say that **you should never use for loops when working with pandas DataFrames**. There might be cases when I'm wrong, but there is almost always a better approach than `for` loops. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Apply Method <a id=apply></a>\n",
    "A third approach we can use is the `apply()` method ([docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply). This built-in pandas method applies a specific function across some axis (rows or columns). In our case, we want to apply a function along the column axis, applying the function to each row. \n",
    "\n",
    "To use apply, you have to define the function you want to apply. This function needs to take in a row, apply the function, and return some value. For our case, we'll define an `area()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.18 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "def area(row):\n",
    "    return row['petal_length'] * row['petal_width']\n",
    "\n",
    "area_column = iris.apply(area, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully this is faster than the previous two approaches. But we are still in the realm of miliseconds. This method is still relatively slow because it continues to go row-by-row through the Dataframe. \n",
    "\n",
    "Since `apply()` is used for a specific purpose, pandas is able to make assumptions and include optmizations that the more general approaches don't have access to. For example, the `apply()` method implements \n",
    "\n",
    "Its faster because of internal optimizations pandas is able to do. For example, `apply()` checks to see if your function is compatible with its \"fast\" mode ([docs](https://github.com/pandas-dev/pandas/blob/v0.25.3/pandas/core/frame.py#L6737-L6928)). As well, it offloads some of the work to C (a low-level language known for speed), only performing the functions itself in Python. \n",
    "\n",
    "Typically, I almost always avoid using `apply()`. Although, it does make for readable code.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color='tomato'>Up to Here</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Zip & Iterate\n",
    "\n",
    "*Honestly, I'm surprised this is faster than 5 & 6.*   \n",
    "I'm guessing it  must have to do with the specific transformation we are using. Will have to check when I do transformations on a dataset we are using during the workshop. Something a bit more interesting than adding. Edit distance might be nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "areas = []\n",
    "for w, l in zip(iris['petal_length'], iris['petal_width']):\n",
    "    area = w*l\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Use Vectorized Functions\n",
    "Sometimes we can use vectorized functions. These functions operate on entire Series in the DataFrame, instead of individual elements. In addition, these vectorized functions make use of pre-compiled code written in a lower level language like C (the language that was used to build Python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Straight up vector calculations\n",
    "iris['petal_area'] = iris['petal_length'] * iris['petal_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Vectorization with NumPy Arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "areas = np.array(iris['petal_length']) * np.array(iris['petal_width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas 1.0 Improvements\n",
    "https://pandas.pydata.org/pandas-docs/stable/whatsnew/v1.0.0.html#using-numba-in-rolling-apply-and-expanding-apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and Beyond\n",
    "For the cases when even these aren't fast enough, you can implement more [advanced techniques](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=vectorization) to enhance the performance. The improvements these advanced techniques can offer differ based on the problem at hand. For example, some techniques use functions and methods that are optimized for boolean comparisons (e.g. greater than) but offer little improvements when working with addition. \n",
    "\n",
    "Also look into `NumExpr` when you need really fast transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "While this difference in speed is hard (if not impossible) to notice for small datasets, it can become hugely consequential when working with large datasets or performing complex calculations. \n",
    "\n",
    "Similar to initialization, we have to remember that optimizing your code should not be placed at the expense of functionality. Often its best to get something that works before going back and finding the most optimal solution. However, I hope that by introducing a couple of Do's and Don'ts your first insticts can help you avoid some of the easiest traps.\n",
    "\n",
    "\n",
    "\n",
    "Checkout: https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=vectorization -- take an image of the big warning here actually\n",
    "\n",
    "*Adapted from/Inspired by a lecture by Greg Baker, SFU*\n",
    "\n",
    "1. Never directly iterate over the rows in a DataFrame. \n",
    "2. ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Work Time <a id='open'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
