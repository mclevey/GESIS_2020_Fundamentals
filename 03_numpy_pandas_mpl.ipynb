{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Analysis with Python \n",
    "\n",
    "## Day 3: Scientific Computing with NumPy, Pandas, Matplotlib, and Seaborn \n",
    "\n",
    "49th [GESIS Spring Seminar: Digital Behavioral Data](https://training.gesis.org/?site=pDetails&pID=0xA33E4024A2554302B3EF4AECFC3484FD)   \n",
    "Cologne, Germany, March 2-6 2010\n",
    "\n",
    "### Course Developers and Instructors \n",
    "\n",
    "* Dr. [John McLevey](www.johnmclevey.com), University of Waterloo (john.mclevey@uwaterloo.ca)     \n",
    "* [Jillian Anderson](https://ca.linkedin.com/in/jillian-anderson-34435714a?challengeId=AQGaFXECVnyVqAAAAW_TLnwJ9VHAlBfinArnfKV6DqlEBpTIolp6O2Bau4MmjzZNgXlHqEIpS5piD4nNjEy0wsqNo-aZGkj57A&submissionId=16582ced-1f90-ec15-cddf-eb876f4fe004), Simon Fraser University (jillianderson8@gmail.com) \n",
    "\n",
    "<hr>\n",
    "\n",
    "### Overview \n",
    "\n",
    "High-level overview coming soon... \n",
    "\n",
    "### Plan for the Day\n",
    "\n",
    "1. [Introduction to NumPy](#numpy)\n",
    "    * Arrays \n",
    "2. [Introduction to Pandas](#pandas)\n",
    "    * Series \n",
    "    * Dataframes \n",
    "    * Groupby and descriptive statistics\n",
    "3. [Simple Data Visualization](#viz)\n",
    "    * A gentle introduction to Matplotlib \n",
    "    * Data Visualization with Seaborn \n",
    "4. [Best practices when working with Pandas Series and DataFrames](#pandasbp)\n",
    "    * Understanding how data is stored in Pandas\n",
    "    * Initialization\n",
    "    * Transformation\n",
    "5. [Open Work Time](#open)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NumPy<a id='numpy'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas<a id='pandas'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Data Visualization<a id='viz'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best practices when working with Pandas Series and DataFrames <a id='pandasbp'></a>\n",
    "\n",
    "From [pandas](https://pandas.pydata.org/):\n",
    ">pandas is a **fast**, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. \n",
    "\n",
    "This is all true, with a pretty large caveat. Pandas is fast (and generally efficient), if you avoid some of the common pitfalls. Unfortunately, these traps are easy to fall for and many pandas users (even senior data scientists) don't know they might be slowing their code down 10-1000x. These people will often be hesitant to use pandas on large datasets and may dissuade others from using the library. \n",
    "\n",
    "However, by understanding a little about what is going on in the backend, we can avoid the worst of the problems and write relatively fast pandas code. \n",
    "\n",
    "[How is data stored in pandas?](#storage)   \n",
    "[Efficient Transformation](#transform)   \n",
    "[Efficient Initialization](#init)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is data stored in Pandas? <a id='storage'></a>\n",
    "\n",
    "### Series\n",
    "\n",
    "### DataFrames\n",
    "DataFrames are really just a collection of Series, with each column corresponding to its own Series. As we mentioned above, each item in a Series (or column) is stored right after the one before it. This means that the entire column is stored within a single range of memory.\n",
    "\n",
    "However, the multiple Series (columns) that make a DataFrame can be stored anywhere in memory and are often not stored side-by-side. \n",
    "\n",
    "We can think of this like a grocery list for sandwiches. Lets imagine that each kind of sandwich we make is composed of 1 type of bread, 1 type of  meat and 1 type of vegetable. We could arrange our grocery list into a table like this: \n",
    "\n",
    "| sandwich_id | bread_type | meat_type  | vegetable_type |\n",
    "|-------------|------------|------------|----------------|\n",
    "| 0           | sourdough  | ham        | lettuce        |\n",
    "| 1           | baguette   | turkey     | tomato         |\n",
    "| 2           | rye        | roast beef | onion          |\n",
    "\n",
    "We buy all of our bread products from a bakery, meat from a deli, and vegetables from a grocer. The result is that to get everything in a column, you can go to one location (e.g. bakery for bread_type). But to get everything from a row you will have to visit all three locations. \n",
    "\n",
    "This means that is it really fast to access an entire column, but really slow to access a row. Lets check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column\\n------\")\n",
    "%timeit sl = iris['petal_length']\n",
    "\n",
    "print(\"Row\\n------\")\n",
    "%timeit example_1 = iris.iloc[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This difference in speed is more than a 50x difference! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations <a id='transform'></a>\n",
    "One instance where the underlying storage structure and its consquence on speed is when applying transformations (calculations or other functions) to a DataFrame. \n",
    "\n",
    "A common case of this is when we want to add a new column to our DataFrame based on values in other columns. For example, we may want to:  \n",
    "* Extract month from a data column\n",
    "* Calculate area from width & length columns\n",
    "* Predict whether a flight will be late by applying a deep learning model to the values of 5 other columns. \n",
    "\n",
    "There is a long list of transformations we might be interested in, many of which operate on a single row, independent of other rows. \n",
    "\n",
    "There are many ways to implement transformations in pandas, some of which take advantage of how DataFrames are stored and others that do not. Below, we are going to look at __X__ methods for implementing transformations:\n",
    "1. [For Loops](#for)\n",
    "2. [Itterows]\n",
    "2. [Apply Method]\n",
    "3. [Zip & Iterate]\n",
    "4. \n",
    "\n",
    "We will use a common example across transformation methods allowing us to compare the speed of each one. For each method we will create a new column called `petal_area` by multiplying `petal_length` by `petal_width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- ideally this is changed to a dataset we are using \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "iris.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 For Loops <a id='for'></a>\n",
    "Perhaps one of the most obvious ways to approach a transformation is to go row-by-row through the dataframe, doing the necessary transformations one at a time. A simple way to do this is using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Looping over the rows\n",
    "area = []\n",
    "for i in range(0, len(iris)):\n",
    "    row = iris.loc[i]\n",
    "    i_area = row['petal_length'] * row['petal_width']\n",
    "    area.append(i_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, the `%%timeit` line is called a [magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#). The `timeit` magic lets us time the execution of a Python statement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  `iterrows()`\n",
    "`iterrows()` is a built-in Pandas method made for the purpose of iterating the rows in a Pandas DataFrame. The method creates a generator (a special Python data type) which we can then use a for loop to iterate through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "areas = []\n",
    "for idx, row in iris.iterrows():\n",
    "    area = row['petal_length'] * row['petal_width']\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "def my_area(row):\n",
    "    return row['petal_length'] * row['petal_width']\n",
    "\n",
    "areas = iris.apply(my_area, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Zip & Iterate\n",
    "\n",
    "*Honestly, I'm surprised this is faster than 5 & 6.*   \n",
    "I'm guessing it  must have to do with the specific transformation we are using. Will have to check when I do transformations on a dataset we are using during the workshop. Something a bit more interesting than adding. Edit distance might be nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "areas = []\n",
    "for w, l in zip(iris['petal_length'], iris['petal_width']):\n",
    "    area = w*l\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Use Vectorized Functions\n",
    "Sometimes we can use vectorized functions. These functions operate on entire Series in the DataFrame, instead of individual elements. In addition, these vectorized functions make use of pre-compiled code written in a lower level language like C (the language that was used to build Python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Straight up vector calculations\n",
    "iris['petal_area'] = iris['petal_length'] * iris['petal_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Vectorization with NumPy Arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "areas = np.array(iris['petal_length']) * np.array(iris['petal_width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas 1.0 Improvements\n",
    "https://pandas.pydata.org/pandas-docs/stable/whatsnew/v1.0.0.html#using-numba-in-rolling-apply-and-expanding-apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and Beyond\n",
    "For the cases when even these aren't fast enough, you can implement more [advanced techniques](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=vectorization) to enhance the performance. The improvements these advanced techniques can offer differ based on the problem at hand. For example, some techniques use functions and methods that are optimized for boolean comparisons (e.g. greater than) but offer little improvements when working with addition. \n",
    "\n",
    "Also look into `NumExpr` when you need really fast transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "While this difference in speed is hard (if not impossible) to notice for small datasets, it can become hugely consequential when working with large datasets or performing complex calculations. \n",
    "\n",
    "Similar to initialization, we have to remember that optimizing your code should not be placed at the expense of functionality. Often its best to get something that works before going back and finding the most optimal solution. However, I hope that by introducing a couple of Do's and Don'ts your first insticts can help you avoid some of the easiest traps.\n",
    "\n",
    "\n",
    "\n",
    "Checkout: https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=vectorization -- take an image of the big warning here actually\n",
    "\n",
    "*Adapted from/Inspired by a lecture by Greg Baker, SFU*\n",
    "\n",
    "1. Never directly iterate over the rows in a DataFrame. \n",
    "2. ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Work Time <a id='open'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
