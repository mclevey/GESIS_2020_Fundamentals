{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Analysis with Python \n",
    "\n",
    "## Day 2: Collecting Data from the Web\n",
    "\n",
    "49th [GESIS Spring Seminar: Digital Behavioral Data](https://training.gesis.org/?site=pDetails&pID=0xA33E4024A2554302B3EF4AECFC3484FD)   \n",
    "Cologne, Germany, March 2-6 2010\n",
    "\n",
    "### Course Developers and Instructors \n",
    "\n",
    "* Dr. [John McLevey](www.johnmclevey.com), University of Waterloo (john.mclevey@uwaterloo.ca)     \n",
    "* [Jillian Anderson](https://ca.linkedin.com/in/jillian-anderson-34435714a?challengeId=AQGaFXECVnyVqAAAAW_TLnwJ9VHAlBfinArnfKV6DqlEBpTIolp6O2Bau4MmjzZNgXlHqEIpS5piD4nNjEy0wsqNo-aZGkj57A&submissionId=16582ced-1f90-ec15-cddf-eb876f4fe004), Simon Fraser University (jillianderson8@gmail.com) \n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "### Overview \n",
    "\n",
    "High-level overview coming soon... \n",
    "\n",
    "### Plan for the Day\n",
    "\n",
    "1. [What you need to know about how the Internet works to collect data from the web](#wyntk)\n",
    "2. [Scraping the Web](#scrape)\n",
    "    * How to scrape text and tables from static websites with BeautifulSoup\n",
    "    * An overview of working with (a) multiple pages and (2) interactive content \n",
    "3. [Collecting data via Application Programming Interfaces](#apis)\n",
    "    * Understanding APIs \n",
    "    * The Twitter API \n",
    "    * The Guardian API \n",
    "4. [Simple text processing with web data](#text)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What you need to know about how the Internet works to collect data from the web <a id='wyntk'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Web <a id='scrape'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data via Application Programming Interfaces <a id='apis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding APIs\n",
    "\n",
    "Application Programming Interfaces offer an alternative way to access data from online sources. It provides an explicit _interface_ to the data behind the website. It explicitly defines how you can request data from the website and what format you will receive the data. \n",
    "\n",
    "### What APIs are Made of\n",
    "* Endpoints\n",
    "* Queries (?)\n",
    "* Filters (?) \n",
    "\n",
    "\n",
    "### APIs vs Web Scraping\n",
    "\n",
    "Benefits: \n",
    "* Structured data (for the most part). \n",
    "* Regulated or Controlled by \n",
    "* Usually well documented by the company \n",
    "* Maintained by the company/organization (not a random person on github)\n",
    "* Explicitly allowable\n",
    "\n",
    "Drawbacks: \n",
    "* You get the data you get \n",
    "* Relies on the company making updates to the codebase (changes may not be reflected) whereas with open-source someone can just make the change. \n",
    "* Rate limits & other restrictions based on company business decisions rather than technical limitations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Guardian API\n",
    "The Guardian's API allows us to query and download data related to their published articles. \n",
    "\n",
    "API token -- important! (move to Understanding APIs or a Best Practices section under APIs) never store your API token in a git repo or any other publically available location. This is incredibly dangerous. It allows other people to use your credentials to access the API, making any of there requests tracable to you. In the case of Guardian, this is problematic b/c if someone were to get a hold of your key and use it to launch a DOS attack on Guardian, its quite likely your token would be revoked and you'd be unable to request a new one in the future. \n",
    "\n",
    "To solve this problem, I would reccommend creating a `cred.py` file that can be stored on your computer and imported by the Python files you are working in. Ideally, this is stored in one location on your machine that all your python packages can import from (something in PATH). (Need to look into best practices on this). Then, this file is stored outside the repo. If for some reason you need to store this file in the same directory as your python file (and thus inside the repo directory) make sure to add `cred.py` to the `.gitignore` file. \n",
    "\n",
    "### Rate Limits\n",
    "Rate limits are defined by the [type of key](https://open-platform.theguardian.com/access/) you've applied for. Its important to understand how these limits are controlled. For example, some websites and companies will have built-in measures that reject API requests that go over the rate limit. Others will rely on the honour system and ask you to abide by their guidelines. In those cases you run the risk of being blacklisted if you exceed their rate limits, due to flagging as a denial of service attack. \n",
    "\n",
    "For non-commerical developer keys, you receive: \n",
    "* Up to 12 calls per second\n",
    "* Up to 5,000 calls per day\n",
    "* Access to article text (no image, audio, or video)\n",
    "* Access to a subset of Guardian content (1.9 million pieces)\n",
    "\n",
    "\n",
    "### Endpoints\n",
    "The Guardian API makes available five endpoints: \n",
    "* Content &mdash; returns content. For dev keys only text. Allows querying and filtering to reduce what is returned.  \n",
    "* Tags &mdash; will return all API tags (> 50, 000). These tags can be used in other quries. \n",
    "* Sections &mdash; logical grouping of content\n",
    "* Editions &mdash; the content for each of the three regional main pages\n",
    "* Single Item &mdash; will return all data related to a specific item (content, tag, or section) in the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the API\n",
    "The Guardian maintains and supports one client &mdash; the Scala client library. However, other clients are supported by the community. We will use the [Python client library], one of the community-built clients, to access the Guardian API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "### Learning More\n",
    "If you want to learn more about the Guardian API or want to ask questions of others working with the API, I would recommend checking out the [Guardian API talk board]() and the [Guardian developer blog](). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wikipedia API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple text processing with web data <a id='text'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
